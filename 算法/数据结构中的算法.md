# 数据结构中的算法

---

# 图
## 图的基本概念

- 图：图（Graph）是由顶点的有穷非空集合和顶点之间边的集合组成，通常表示为：G(V,E)，其中，G表示一个图，V是图G中顶点的集合，E是图G中边的集合。
- 无向边：若顶点 x 和 y 之间的边没有方向，则称该边为无向边(x, y)，(x, y) 与 (y,x) 意义相同，表示 x 和 y 之间有连接。
- 无向图：若图中任意两个顶点之间的边均是无向边，则称该图为无向图
- 有向边：若顶点 x 和 y 之间的边有方向，则称该边为有向边`<x, y>`。此时的边也称为“弧”，x称为弧尾，y称为弧头。
- 有向图：若图中任意两个顶点之间的边均是有向边，则称该图为有向图
- 完全图：如果顶点个数是n，那么有1/2n(n-1)条边的无向图称为完全图。也就是说，任意两个顶点之间都有边相连。
- 有向完全图：如果顶点个数是n，那么有n(n-1)条弧的有向图称为有向完全图。也就是说，任意两个顶点之间都有两条弧相连。
- 稀疏图：有很少条边或弧(如`e<nlogn`)的图称为稀疏图，反之称为稠密图。
- 权：有时图的边或弧具有与它相关的数，这种与图的边或弧相关的数叫做权。
- 网：带权的图通常称为网。
- 子图：如果图G1中的每一条边或弧都是图G2中边或弧的子集，每一个顶点都是G2的顶点的子集，那么称G1是G2的子图。
- 邻接点、度
    - 对于无线图，如果两个顶点v1和v2之间有边相连，那么称v1和v2互为临界点，边(v1,v2)依附于顶点v1和v2，或者说边(v1,v2)和顶点v1、v2相关联。顶点v的度是和顶点相关联的边的数目。
    - 对于有向图，如果弧两个顶点之间有弧`<v1,v2>`相连，且箭头方向由v1指向v2，那么称v1邻接到v2，v2邻接自v1。弧`<v1,v2>`和顶点v1、v2相关联。以顶点v为头的弧数称为v的入度，以v为尾的弧数称为v的出度。
- 回路、环、简单路径：第一个顶点和最后一个顶点相同的路径称为回路或环。顶点不重复出现的路径称为简单路径。除了第一个顶点和最后一个顶点之外，其余顶点不重复出现的回路，称为简单回路或简单环。
- 连通性：连通性是图中另一个重要的概念。对于无向图而言，如果它的每个顶点都能通过某条路径到达其他顶点，那么我们称它为联通的。如果该条件在有向图中同样成立，则称该图是强连通。尽管无向图可能不是连通的，但它扔然可能包含连通的部分，这部分分支为连通分支。如果有向图中只有部分是强连通的，则该部分称为强连通分支。
- 生成树：一个连通图的生成树是一个极小联通子图，它含有图中的全部顶点，但只有足以构成一棵树的n-1条边。
- 关节点和重连通图：假如在删除顶点v以及和v相关联的各边之后，将图的一个联通分量分割成两个或两个以上的联通分量，则称顶点v为图的一个关节点。一个没有关节点的连通图称为重连通图。

参考[数据结构之图的定义及基本术语](https://blog.csdn.net/u014754841/article/details/79379243)

## 图的存储结构
### 邻接矩阵 

### 邻接表

## 图的遍历
### 深度优先
深度优先遍历的主要思想就是：首先以一个未被访问过的顶点作为起始顶点，沿当前顶点的边走到未访问过的顶点，当没有未访问过的顶点时，则回到上一个顶点，继续试探访问别的顶点，直到所有的顶点都被访问过。

所以，深度优先是一个递归的过程，可以用栈来做。

时间复杂度：
- 存储结构为邻接矩阵时：查找每个顶点的邻接点所需要的时间为O(n^2)，n为顶点数
- 存储结构为邻接表时：查找每个邻接点所需时间为O(e)，e为边或弧数。此时深度优先的复杂度为O(n+e)

### 广度优先
广度优先遍历的思想就是：首先以一个未被访问的顶点，访问其所有的相邻的顶点，然后对每个相邻的顶点，再访问他们相邻的未被访问过的顶点，直到所有的顶点都被访问过，遍历结束。

广度优先的遍历过程类似于树的按层次遍历的过程，比较适合用队列来做。

广度优先的时间复杂度和深度优先是相同的。

参考[深度优先遍历和广度优先遍历](https://blog.csdn.net/u012193416/article/details/82177321)

## 无向图的最小生成树

### 普利姆算法
#### 算法描述
假设有一个存储点的集合V[]，首先选取一个点进入集合内，找到与这个点相连接的点里面权值最小的放入集合中，然后每次在剩余点中再选取与集合内任意一点连接的点的边的权值最小的那个点放入集合，直到所有的点都在集合内。过程如下图所示：

<div align="center">
<img src="https://raw.githubusercontent.com/adamhand/LeetCode-images/master/prim.jpg" width="500">
</div>

可以看到，普利姆算法专注于**“点”**，每次往集合中放一个点。

**注意：**如果在某次选取边的时候遇到两条边权值相等的情况，那么可以随便选一条，这样得到的图形状可能不同，但是权值的和是相等的。

#### 算法实现


### 克鲁斯卡尔算法

## 有向无环图和拓扑排序
### 有向无环图
一个无环的有向图称为有向五环图，简称DAG(Directed Acyclic Graph)图。

### 拓扑排序
对于任何有向图而言，其拓扑排序为其所有结点的一个线性排序。该排序满足这样的条件——对于图中的任意两个结点u和v，若存在一条有向边从u指向v，则在拓扑排序中u一定出现在v前面。一个有向图可能存在多个拓扑排序。

拓扑排序主要的用途有两个：

- 判断一个有向图是不是有环
- 解决有向图中的依赖解析（dependency resolution）问题

对于一个无向图来说，判断是否存在环比较简单，只需要看一下深度优先遍历过程中是否遇到回边(即指向已经访问过的顶点的边)，但是有向图就比较复杂，需要用拓扑排序来做。

关于依赖关系，如果存在一条从v1指向v2的弧，那么就说v2依赖于v1。举例来说，如果我们将一系列需要运行的任务构成一个有向图，图中的有向边则代表某一任务必须在另一个任务之前完成这一限制。那么运用拓扑排序，我们就能得到满足执行顺序限制条件的一系列任务所需执行的先后顺序。当然也有可能图中并不存在这样一个拓扑顺序，这种情况下我们无法根据给定要求完成这一系列任务，这种情况称为循环依赖(circular dependency)(也就是图中产生了循环)。

如果任务i是任务j的先决条件，则图中有弧`<i,j>`，这种用顶点表示活动，用弧表示活动间的优先关系的有向图称为顶点表示活动的网(Activity On Vertex Netword)，简称AOV-网。在AOV-网中，不应该出现环，因为这意味着某项活动以自己为先决条件，这是荒谬的，因此，对给定的AOV-网应该首先判断是否有环，可以用拓扑排序的方法。

拓扑排序的具体过程如下：

- 在有向图中选择一个没有前驱的顶点输出
- 在图中删除该顶点和所有以它为尾的弧
- 重复上述两步，知道全部顶点均以输出，或者当前图中不存在无前驱的顶点为止。后一种情况则说明有向图中存在环。

## 关键路径
用顶点表示事件，弧表示活动，弧上的权值表示活动持续的时间的有向图叫AOE（Activity On Edge Network）网。AOE网常用于估算工程完成时间。

AOE-网中的几个概念：
- 源点：入度为0的顶点，它表示一个工程的开始
- 汇点：出度为0的顶点，它表示一个工程的结束
- 路径长度：路径上各个活动所持续的时间之和
- 在AOE网中，从源点到汇点具有最大长度的路径称为关键路径，在关键路径上的活动称为关键活动。一个AOE-图可以有多个管夹路径

### 关键路径计算
首先得了解几个概念，对活动i来说：

- 活动(弧)开始的最早时间e(i)，只要活动的依赖活动都完成，就可以开始
- 活动开始的最晚时间l(i)，是指为了使项目在要求完工时间内完成，某项活动必须开始的最迟时间
- 事件(顶点)开始的最早时间ve(i)
- 事件开始的最晚时间vl(i)

定义e(i)=l(i）的活动叫关键活动

如果活动i由弧`<j,k>`表示，其持续时间记为`dut(<j,k>)`，则有如下关系：

- `e(i) = ve(j)`，即一条弧最早的开始时间等于前面的顶点的最早开始时间
- `l(i) = vl(k) - dut(<j,k>)`，一条弧最晚开始时间等于后面的顶点最晚开始时间减去弧花费的时间

需要求e(i)和l(i)首先得求得ve(j)和ve(k)

求ve(j)需要从源点向汇点推倒，求最大值。举个例子，比如顶点j之前有两条弧，一条长9，一条长10，那么j最早开始时间必须等长为10的弧执行完毕。计算公式为：

- `ve(j) = Max{ve(i) + dut(<i,j>)}`

求ve(k)需要从汇点向源点推到，求最小值。举个例子，如果顶点k之后有两条弧，一条长9，一条长10，那么顶点k的最晚开始时间应该由长为9的那条弧决定。计算公式为：

- `vl(k) = Min{vl(m) - dut(<k,m>)}`

关键路径的计算过程如下：

- 输入e条弧`<j,k>`，建立AOE网的存储结构
- 从源点v1出发，令ve(1)=0，按照拓扑排序求其余顶点的最早开始时间，如果发现有环，算法终止
- 从汇点vn出发，令vl(n)=ve(n），按照逆序拓扑排序求剩余节点的最迟开始时间
- 根据各顶点的ve和vl值，求每条弧s（活动）的最早开始时间e(s)和最晚开始时间l(s)，其中e(s)=l(s)的为关键活动

参考[关键路径算法演示（AOE网）](https://www.jianshu.com/p/1857ed4d8128)

## 最短路径
### 迪杰斯特拉算法
迪杰斯特拉算法是一种求单源最短路径的算法，所谓单源，是指定一个点（源点）到其余各个顶点的最短路径。Dijkstra算法算是**贪心思想**实现的，首先把起点到所有点的距离存下来找个最短的，然后松弛一次再找出最短的，所谓的松弛操作就是，遍历一遍看通过刚刚找到的距离最短的点作为中转站会不会更近，如果更近了就更新距离，这样把所有的点找遍之后就存下了起点到其他所有点的最短距离。

迪杰斯特拉算法的主要步骤如下：

- 开始时，需要指定一个起点v，并初始化一个集合用来记录其余各点到v点直接边的最短路径，如果没有直接边相连，则初始化为无穷大
- 接着从除v以外的顶点中选择一个距离v最近的顶点，之后以该顶点为中转，如果其余顶点经过该顶点到v的最短路径比原来的要小，那么更新这些顶点到v的最短路径
- 重复上述操作，直到所有的顶点全部被选择完

迪杰斯特拉算法的复杂度为O(n^2)，n为顶点的个数。

### 弗洛伊德算法
弗洛伊德算法是解决任意两点间的最短路径的一种算法，所以又称为多源最短路径算法。可以正确处理有向图或负权的最短路径问题，同时也被用于计算有向图的传递闭包。时间复杂度为O(N^3)，空间复杂度为O(N^2)。

Floyd算法是一个经典的动态规划算法。用通俗的语言来描述的话，首先我们的目标是寻找从点i到点j的最短路径。从动态规划的角度看问题，我们需要为这个目标重新做一个诠释。

从任意节点i到任意节点j的最短路径不外乎2种可能，1是直接从i到j，2是从i经过若干个节点k到j。所以，我们假设Dis(i,j)为节点u到节点v的最短路径的距离，对于每一个节点k，我们检查Dis(i,k) + Dis(k,j) < Dis(i,j)是否成立，如果成立，证明从i到k再到j的路径比i直接到j的路径短，我们便设置Dis(i,j) = Dis(i,k) + Dis(k,j)，这样一来，当我们遍历完所有节点k，Dis(i,j)中记录的便是i到j的最短路径的距离。

弗洛伊德算法的具体步骤如下：

- 从任意一条单边路径开始。所有两点之间的距离是边的权，如果两点之间没有边相连，则权为无穷大。
- 对于每一对顶点 u 和 v，看看是否存在一个顶点 w 使得从 u 到 w 再到 v 比己知的路径更短。如果是更新它。

参考：
[最短路径—Dijkstra算法和Floyd算法](https://www.cnblogs.com/biyeymyhjob/archive/2012/07/31/2615833.html)</br>
[透彻理解迪杰斯特拉算法](https://blog.csdn.net/mu399/article/details/50903876)</br>
[【数据结构】最短路径之迪杰斯特拉(Dijkstra)算法与弗洛伊德(Floyd)算法](https://www.jianshu.com/p/c96c40801d7f)</br>
[Dijkstra算法图文详解](https://blog.csdn.net/lbperfect123/article/details/84281300)</br>

# 哈希表
## 常用的哈希函数
### 直接定址法
取关键字或者关键字的某个线性函数值作为哈希地址,即：
<center>
H(Key)=Key或者H(Key)=a*Key+b(a,b为整数),
</center>

这种散列函数也叫做自身函数.如果H(Key)的哈希地址上已经有值了,那么就往下一个位置找,知道找到H(Key)的位置没有值了就把元素放进去。

### 数字分析法
分析一组数据,比如一组员工的出生年月,这时我们发现出生年月的前几位数字一般都相同,因此,出现冲突的概率就会很大,但是我们发现年月日的后几位表示月份和具体日期的数字差别很大,如果利用后面的几位数字来构造散列地址,则冲突的几率则会明显降低.因此数字分析法就是找出数字的规律,尽可能利用这些数据来构造冲突几率较低的散列地址。

### 平方取中法
取关键字平方后的中间几位作为散列地址.一个数的平方值的中间几位和数的每一位都有关。因此，有平方取中法得到的哈希地址同关键字的每一位都有关，是的哈希地址具有较好的分散性。该方法适用于关键字中的每一位取值都不够分散或者较分散的位数小于哈希地址所需要的位数的情况。

### 折叠法
折叠法即将关键字分割成位数相同的几部分,最后一部分位数可以不同,然后取这几部分的叠加和(注意:叠加和时去除进位)作为散列地址。数位叠加可以有移位叠加和间界叠加两种方法。移位叠加是将分割后的每一部分的最低位对齐,然后相加;间界叠加是从一端向另一端沿分割界来回折叠,然后对齐相加。

### 随机数法
选择一个随机函数，取关键字的随机函数值作为它的哈希地址，即H(key)=random(key)。通常用于关键字长度不同的场合。

### 除留余数法
取关键字被某个不大于散列表表长m的数p除后所得的余数为散列地址。即H(Key)=Key MOD p,p<=m。不仅可以对关键字直接取模,也可在折叠、平方取中等运算之后取模。对p的选择很重要，一般取素数或m，若p选得不好，则很容易产生冲突。一般p取值为表的长度tableSize。

## 常用的处理冲突的方法
### 开放地址法 
这个方法的基本思想是：当发生地址冲突时，按照某种方法继续探测哈希表中的其他存储单元，直到找到空位置为止。这个过程可用下式描述： 
<center>
H i ( key ) = ( H ( key )+ d i ) mod m ( i = 1,2,…… ， k ( k ≤ m – 1)) 
</center>

其中： H ( key ) 为关键字 key 的直接哈希地址， m 为哈希表的长度， di 为每次再探测时的地址增量。 

采用这种方法时，首先计算出元素的直接哈希地址 H ( key ) ，如果该存储单元已被其他元素占用，则继续查看地址为 H ( key ) + d 2 的存储单元，如此重复直至找到某个存储单元为空时，将关键字为 key 的数据元素存放到该单元。 

增量 d 可以有不同的取法，并根据其取法有不同的称呼： 
（ 1 ） d i ＝ 1 ， 2 ， 3 ， …… **线性探测再散列**； 
（ 2 ） d i ＝ 1^2 ，－ 1^2 ， 2^2 ，－ 2^2 ， k^2， -k^2…… **二次探测再散列**； 
（ 3 ） d i ＝ 伪随机序列 **伪随机再散列**； 

**优缺点：**
**线性探测**容易产生“聚集”现象。当表中的第i、i+1、i+2的位置上已经存储某些关键字，则下一次哈希地址为i、i+1、i+2、i+3的关键字都将企图填入到i+3的位置上，这种多个哈希地址不同的关键字争夺同一个后继哈希地址的现象称为“聚集”。聚集对查找效率有很大影响。

**二次探测**能有效避免“聚集”现象，但是不能够探测到哈希表上所有的存储单元，但是至少能够探测到一半。

**例：**设有哈希函数 H ( key ) = key mod 7 ，哈希表的地址空间为 0 ～ 6 ，对关键字序列（ 32 ， 13 ， 49 ， 55 ， 22 ， 38 ， 21 ）按线性探测再散列和二次探测再散列的方法分别构造哈希表。 
**解：**线性探测再散列： 
32 ％ 7 = 4 ； 13 ％ 7 = 6 ； 49 ％ 7 = 0 ； 
55 ％ 7 = 6 发生冲突，下一个存储地址（ 6 ＋ 1 ）％ 7 ＝ 0 ，仍然发生冲突，再下一个存储地址：（ 6 ＋ 2 ）％ 7 ＝ 1 未发生冲突，可以存入。 
22 ％ 7 ＝ 1 发生冲突，下一个存储地址是：（ 1 ＋ 1 ）％ 7 ＝ 2 未发生冲突； 
38 ％ 7 ＝ 3 ； 
21 ％ 7 ＝ 0 发生冲突，按照上面方法继续探测直至空间 5 ，不发生冲突，所得到的哈希表对应存储位置： 
下标： 0 1 2 3 4 5 6 
49 55 22 38 32 21 13 

**注意：对于利用开放地址法处理冲突所产生的哈希表中删除一个元素时需要谨慎，不能直接地删除，因为这样将会截断其他具有相同哈希地址的元素的查找地址（开放地址法查找时如果遇到key为空，就停止查找，所以，后面的元素查找不到），所以，通常采用设定一个特殊的标志以示该元素已被删除。** 

###链地址法 
链地址法解决冲突的做法是：如果哈希表空间为 0 ～ m - 1 ，设置一个由 m 个指针分量组成的一维数组 ST[ m ], 凡哈希地址为 i 的数据元素都插入到头指针为 ST[ i ] 的链表中。这种方法有点近似于邻接表的基本思想，且这种方法适合于冲突比较严重的情况。

### 再哈希法
<center>
Hi = RHi(key)
</center>

RHi是不同的哈希函数，即在产生地址冲突时计算另一个哈希函数地址，直到冲突不再发生。这种方法不易产生“聚集”，但增加了计算的时间。

### 建立一个公共溢出区
设立一个溢出表，不管哈希函数得到的哈希地址是什么，一旦发生冲突，都填入溢出表。在溢出表中按照顺序查找。

## 哈希表的装填因子
装填因子 = （哈希表中的记录数） /  （哈希表的长度）

装填因子是哈希表装满程度的标记因子。值越大，填入表中的数据元素越多，产生冲突的可能性越大。

## 平均查找长度
具体的公式参看《数据结构(C语言版)》P261。

例子：假设散列表的长度是13，三列函数为H(K) = k % 13，给定的关键字序列为{32， 14， 23， 01， 42， 20， 45， 27， 55， 24， 10， 53}。分别画出用线性探测法和拉链法解决冲突时构造的哈希表，并求出在等概率情况下，这两种方法的查找成功和查找不成功的平均查找长度。

**(1)线性探测再散列**
使用线性探测再散列处理冲突，得到的哈希表如下：
<center>
<img src="https://raw.githubusercontent.com/adamhand/LeetCode-images/master/hash.jpg" width="500">
</center>

**查找成功时**的查找次数等于插入元素时的比较次数,查找成功的平均查找长度为：
`ASL = （1+2+1+4+3+1+1+3+9+1+1+3)/12 = 2.5`

**计算查找不成功**的次数就直接找关键字到第一个地址上关键字为空的距离即可，因为查找不成功的条件只有一种：找到了一个空地址。

哈希表中地址0的关键字为空，所以只需要计算地址1~12到地址0的距离即可，分别为：12,11,10,9,8,7,6,5,4,3,2,1。所以查找不成功的平均查找次数为：
`ASL = （1+2+3+4+5+6+7+8+9+10+11+12）/ 13 = 91/13`

**注意：查找成功时，分母为哈希表元素个数，查找不成功时，分母为哈希表长度。（此处存在疑问）**

**(2)链地址法**
用链地址法解决冲突得到的哈希表如下：
<center>
<img src="https://raw.githubusercontent.com/adamhand/LeetCode-images/master/hash_1.jpg" width="500">
</center>

查找成功时的平均查找长度：
`ASL = (1*6+2*4+3*1+4*1)/12 = 7/4`

查找不成功时的平均查找长度：
`ASL = (4+2+2+1+2+1)/13 = 12/13`

---
参考：
[开放地址法与链表法的优缺点及其实现](https://blog.csdn.net/mark555/article/details/22038151)
[哈希表——线性探测法、链地址法、查找成功、查找不成功的平均长度](https://blog.csdn.net/u011080472/article/details/51177412)
[解决哈希表的冲突-开放地址法和链地址法](https://blog.csdn.net/w_fenghui/article/details/2010387)
[哈希表等概率情况下查找成功和查找不成功的平均查找长度的计算](https://blog.csdn.net/wangran51/article/details/8826633/)

---

# 树
树是n个节点的有限集，在任意一个非空树中：

- 有且仅有一个特定的节点称为根(root)节点
- 剩余的节点可以分为多个互不相交的有限集，其中每一个集合本身又是一棵树，称为根的**子树**

- 度：节点拥有子树的数量称为节点的**度**。
- 叶子节点、叶节点、终端节点：度为0的节点叫做叶子节点，也叫叶节点、终端节点，其实就是没有子节点的节点，或者说没有子树的节点
- 双亲节点、父节点：父节点就是一个节点上头的那个节点，如果一个节点包含若干子节点，那么这个节点就是这些子节点的父节点，也叫双亲节点
- 兄弟节点：拥有相同父节点的节点互称为兄弟节点
- 树的高度、深度
    - 树的深度是从根节点开始、自顶向下逐层累加（根节点的高度是1）助记：深度从上到下
    - 树的高度是从叶节点开始、自底向上逐层累加（叶节点的高度是1）助记：高度由下向上
    - 虽然树的高度和深度一样，但是具体到某个节点上，其高度和深度通常是不一样的。
- 堂兄弟节点：堂兄弟节点是同一层，父节点不同，或者说双亲节点在同一层的节点称之为堂兄弟节点
- 森林：由m棵不相交的树组成的集合，叫做森林


## 二叉树(Binary Tree)
二叉树是一种树结构，它的特定是每个节点至多只有两棵子树，并且二叉树的子树有左右之分，其次序不能任意颠倒。

### 完全二叉树和满二叉树
- 满二叉树：除最后一层无任何子节点外，每一层上的所有结点都有两个子结点。也可以这样理解，除叶子结点外的所有结点均有两个子结点。节点数达到最大值，所有叶子结点必须在同一层上。
- 完全二叉树：若设二叉树的深度为h，除第 h 层外，其它各层 (1～(h-1)层) 的结点数都达到最大个数，第h层所有的结点都连续集中在最左边，这就是完全二叉树。

### 二叉树的性质
- 性质1：在二叉树的第i层上至多有2^(i-1)个结点（i>=1）
- 性质2：深度为k的二叉树至多有(2^k)-1个结点（k>=1）
- 性质3：对任何一棵二叉树T，如果其终端结点数为n0,度为2的结点数为n2，则n0 = n2+1。
- 性质4：具有n个结点的完全二叉树的深度为[log2n ] + 1([X]表示不大于X的最大整数)。
- 性质5：如果对一颗有n个结点的完全二叉树（其深度为[log2n ] + 1）的结点按层序编号（从第1层到第[log2n ] + 1层，每层从左到右），对任一结点i(1<=i<=n)有：
    - 如果i=1，则结点i是二叉树的根，无双亲；如果i>1，则其双亲是结点[i/2]。
    - 如果2i>n,则结点i无左孩子（结点i为叶子结点）；否则其左孩子是结点i。
    - 如果2i+1>n,则结点i无右孩子；否则其右孩子是结点2i+1。

### 树的遍历


### 赫夫曼树
赫夫曼树称为最优二叉树。赫夫曼树具有一个性质，它的带权路径长度是最小的。

## 二叉搜索树(不具备平衡性)
二叉搜索树或者是一棵空树，或者具有如下性质：

- 若它的左子树不为空，则左子树上所有节点的值均小于它的根节点的值
- 若它的右子树不为空，则右子树上所有节点的值均大于它的根节点值
- 它的左子树和右子树也分别为二叉排序树

当二叉搜索树变得很不平衡的之后，搜索的复杂度会比较大。

## 平衡二叉树(又称AVL树)
关于AVL树，不同的书有不同的解释，严蔚敏的《数据结构(C语言版)》说AVL是平衡二叉树。而Mark Allen Weiss的《数据结构与算法分析-C语言描述》中说AVL树是平衡二叉搜索树。下面以Mark的为准。

## 红黑树(相对平衡的二叉查找树)

红黑树的定义如下：

- 任何一个节点都有颜色，黑色或者红色
- 根节点是黑色的
- 父子节点之间不能出现两个连续的红节点
- 任何一个节点向下遍历到其子孙的叶子节点，所经过的黑节点个数必须相等
- 空节点被认为是黑色的

## B+/B-树
### B-树
B-树其实不叫B减树，中间的“-”只是一个连接符，它就叫B树。B-树是一种平衡的多路查找树，它在文件系统中很有用，有如下性质：

一棵n阶的B-树，或者为空树，或者满足如下条件：
- 树中每个节点至多有m棵子树；
- 若根节点不是叶子节点，则至少有2棵子树；
- 除根节点之外的所有非终端节点至少[m/2]有棵子树。([X]表示不大于X的最大整数)
- 所有非叶子节点都包含信息数据
- 所有的叶子节点都出现在同一层次上，且不带任何信息，也是为了保持算法的一致性。

### B+树
一棵m阶的B+树和m阶的B-树的差异在于：

- 有n棵子树的节点含有n个关键字；
- 所有的叶子节点包含了全部关键字的信息，及指向这些关键字记录的指针，且叶子节点本身按关键字大小自小到大顺序链接；
- 所有非终端节点可以看成是索引部分，节点中仅含有其子树中最大（或最小）关键字，所以B+树更像一个索引顺序表；

参考
[数据结构之红黑树](http://dongxicheng.org/structure/red-black-tree/)</br>
[Java数据结构与算法——树（基本概念，很重要）](https://segmentfault.com/a/1190000014741176)</br>
[Java数据结构与算法——二叉树及操作(包括二叉树遍历)](https://segmentfault.com/a/1190000014743964)</br>
[【图解数据结构】 树](https://www.cnblogs.com/songwenjie/p/8878851.html)</br>
[数据结构中的各种树浅谈](https://www.cnblogs.com/shixiangwan/p/7530015.html)</br>
[常用数据结构——树](https://www.jianshu.com/p/912357993486)</br>
[红黑树深入剖析及Java实现](https://zhuanlan.zhihu.com/p/24367771)</br>

