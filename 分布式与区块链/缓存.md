# 缓存

## 什么是缓存
缓存就是数据交换的缓冲区，把读写速度慢的介质的数据保存在读写速度快的介质中，从而提高读写速度。

## 缓存的几个概念
### 命中率
命中率=从缓存返回正确结果数/请求缓存次数，命中率越高，表明缓存的使用率越高。

### 最大元素
缓存中可以存放的最大元素的数量，一旦缓存中元素数量超过这个值，那么将会触发缓存启动清空策略

### 淘汰策略

最常见的策略有三种：

- FIFO（First In First Out）：先进先出策略，在实时性的场景下，需要经常访问最新的数据，那么就可以使用FIFO。
- LRU（Least Recently Used）：最近最久未使用策略，思想是，如果数据最近没有被用到，那么它将来被用到的概率也比较小。淘汰最长时间未被使用的页面，以时间作为参考
- LFU（Least Frequently Used）：最不经常使用策略，优先淘汰一段时间内使用次数最少的数据。淘汰一定时期内被访问次数最少的页面，以次数作为参考。

除此之外，还有一些简单策略比如：

- 根据过期时间判断，清理过期时间最长的元素；
- 根据过期时间判断，清理最近要过期的元素；
- 随机清理；

各种缓存的实现方法可以参见**附录**。

## 缓存问题
### 缓存穿透
是指访问一个一定不存在的key，缓存不起作用，请求会穿透到DB，流量大时D数据库会崩溃。

解决方法：
- 对这些不存在的数据缓存一个空数据；
- 对这类请求进行过滤

### 缓存雪崩
是指缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库，导致数据库崩溃。

解决方法：
- 根据用户行为，不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀
- 使用分布式缓存，每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用
- 使用二级缓存，原缓存失效时可以访问二级缓存
- 进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩

### 缓存一致性
是指缓存中的数据与数据库中的保持一致。

解决办法：
- 在数据更新的同时立即去更新缓存
- 在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新

### 分布式缓存
#### 一致性哈希
Distributed Hash Table（DHT） 是一种哈希分布方式，其目的是为了克服传统哈希分布在服务器节点数量变化时大量数据迁移的问题。

##### **基本原理**
将哈希空间 [0, 2^n-1] 看成一个哈希环，每个服务器节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。

<div align="center">
<img src="https://raw.githubusercontent.com/adamhand/LeetCode-images/master/dht1.jpg" width="500">
</div>

一致性哈希在增加或者删除节点时只会影响到哈希环中相邻的节点，例如下图中新增节点 X，只需要将它前一个节点 C 上的数据重新进行分布即可，对于节点 A、B、D 都没有影响。

<div align="center">
<img src="https://raw.githubusercontent.com/adamhand/LeetCode-images/master/dht2.jpg" width="500">
</div>

#### **虚拟节点**
上面描述的一致性哈希存在数据分布不均匀的问题，节点存储的数据量有可能会存在很大的不同。

数据不均匀主要是因为节点在哈希环上分布的不均匀，这种情况在节点数量很少的情况下尤其明显。

解决方式是通过增加虚拟节点，然后将虚拟节点映射到真实节点上。虚拟节点的数量比真实节点来得多，那么虚拟节点在哈希环上分布的均匀性就会比原来的真实节点好，从而使得数据分布也更加均匀。

如下图所示，NodeA#1 和 NodeB#1是两个真实节点，其余节点为虚拟节点，将定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上，定位到“Node B#1”、“Node B#2”、“Node B#3”三个节点上的数据全部定位到Node B#1上。

<div align="center">
<img src="https://raw.githubusercontent.com/adamhand/LeetCode-images/master/dht3.png" width="500">
</div>

### memcached
memcached仅支持基础的key-value键值对类型数据存储。本身其实不提供分布式解决方案，它的分布式主要是靠客户端的算法来实现的。memcached的服务端其实就是一些memcached服务器的堆积，客户端会通过某些算法将key映射到服务端的某台服务器上。比如常用的方法有**余数计算分散法**和**一致性哈希法**。

#### 余数计算分散法
这种算法的计算方法大概如下：

> CRC($key)%N

客户端首先根据key来计算CRC，然后结果对服务器数进行取模得到memcached服务器节点，但是这种方法会有两个问题：

- 选择的服务器无法连接。一种解决办法是将尝试的连接次数加到key后面，然后进行rehash，这样就会选择下一个服务器，以此类推。
- 当添加或者移除服务器的时候，缓存重组的代价相当大。是这种方法的致命的缺点。

#### 一致性哈希算法
这种方法上面已经介绍过，可以解决增加或删除节点时缓存重组问题，增强可扩展性。

#### 内存管理机制
memcached的内存结构图如下所示：

<div align="center">
<img src="https://raw.githubusercontent.com/adamhand/LeetCode-images/master/memcached_store.png">
</div>

其中有两个重要的概念：

- slab：slab是一个内存块，它是memcached一次申请内存的最小单位。在启动memcached的时候一般会使用参数-m指定其可用内存，但是并不是在启动的那一刻所有的内存就全部分配出去了，只有在需要的时候才会去申请，而且每次申请一定是一个slab。Slab的大小默认为1M（1048576 Byte）
- chunk：一个slab由若干个大小相等的chunk组成。每个chunk中都保存了一个item结构体、一对key和value。一个slab中chunk的大小相等的，但是在不同的slab中chunk的大小并不一定相等

在memcached中按照chunk的大小不同，可以把slab分为很多种类（class），默认情况下memcached把slab分为40类（class1～class40），在class 1中，chunk的大小为80字节，由于一个slab的大小是固定的1048576字节（1M），因此在class1中最多可以有13107个chunk（也就是这个slab能存最多13107个小于80字节的key-value数据）。

memcached内存管理采取预分配、分组管理的方式，分组管理就是上面提到的slab class。内存预分配过程如下：

向memcached添加一个item时候，memcached首先会根据item的大小，来选择最合适的slab class：例如item的大小为190字节，默认情况下class 4的chunk大小为160字节显然不合适，class 5的chunk大小为200字节，大于190字节，因此该item将放在class 5中（显然这里会有10字节的浪费是不可避免的），计算好所要放入的chunk之后，memcached会去检查该类大小的chunk还有没有空闲的，如果没有，将会申请1M（1个slab）的空间并划分为该种类chunk。

例如第一次向memcached中放入一个190字节的item时，memcached会产生一个slab class 2（也叫一个page），并会用去一个chunk，剩余5241个chunk供下次有适合大小item时使用，当用完这所有的5242个chunk之后，下次再有一个在160～200字节之间的item添加进来时，memcached会再次产生一个class 5的slab（这样就存在了2个pages）。

总结来看，memcached内存管理特点是：

- chunk是在page里面划分的，而page固定为1m，所以chunk最大不能超过1m。
- chunk实际占用内存要加48B，因为chunk数据结构本身需要占用48B。
- 如果用户数据大于1m，则memcached会将其切割，放到多个chunk内。
- 已分配出去的page不能回收。

根据上述的特点，需要注意的点有：

- 对于key-value信息，最好不要超过1m的大小
- 同时信息长度最好相对是比较均衡稳定的，这样能够保障最大限度的使用内存
- memcached采用的LRU清理策略，合理设置过期时间，提高命中率

### redis
关于redis，在另个一笔记中已经记录过了，这里就不重复了。记录一下redis和memcached的异同吧。

- Memcached 仅支持字符串类型，而 Redis 支持五种不同的数据类型，可以更灵活地解决问题。
- Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。
- Memcached 本身不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。Redis Cluster 实现了分布式的支持。
- 在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高，例如块的大小为 128 bytes，只存储 100 bytes 的数据，那么剩下的 28 bytes 就浪费掉了。

## 缓存框架
### Ehcache
Ehcache是一款轻量级的纯Java开源缓存框架，Hibernate里面就集成了相关缓存功能。它主要有以下特点：

- 快速，针对大型高并发系统场景，Ehcache的多线程机制有相应的优化改善。
- 简单，很小的jar包，简单配置就可直接使用，单机场景下无需过多的其他服务依赖。
- 支持多种的缓存策略，灵活。
- 缓存数据有两级：内存和磁盘，与一般的本地内存缓存相比，有了磁盘的存储空间，将可以支持更大量的数据缓存需求。
- 具有缓存和缓存管理器的侦听接口，能更简单方便的进行缓存实例的监控管理。
- 支持多缓存管理器实例，以及一个实例的多个缓存区域。

它的框架图如下图所示。

<div align="center">
<img src="https://raw.githubusercontent.com/adamhand/LeetCode-images/master/ehcache.png">
</div>

Ehcache的核心定义主要包括：

- cache manager：缓存管理器，以前是只允许单例的，不过现在也可以多实例了。
- cache：缓存管理器内可以放置若干cache，存放数据的实质，所有cache都实现了Ehcache接口，这是一个真正使用的缓存实例；通过缓存管理器的模式，可以在单个应用中轻松隔离多个缓存实例，独立服务于不同业务场景需求，缓存数据物理隔离，同时需要时又可共享使用。
- element：单条缓存数据的组成单位。
- system of record（SOR）：可以取到真实数据的组件，可以是真正的业务逻辑、外部接口调用、存放真实数据的数据库等，缓存就是从SOR中读取或者写入到SOR中去的。

在上层可以看到，Ehcache提供了对JSR、JMX等的标准支持。它的缓存介质涵盖**堆内存（heap）**、**堆外内存（BigMemory商用版本支持）**和**磁盘**，各介质可独立设置属性和策略。

Ehcache最初是独立的本地缓存框架组件，在后期的发展中，结合Terracotta服务阵列模型，可以支持分布式缓存集群，主要有RMI、JGroups、JMS和Cache Server等传播方式进行节点间通信，如上图左侧部分描述。

当结合Terracotta服务阵列模型做分布式缓存的时候，数据被分为L1层和L2层，**L2数据存储在Terracotta的服务器阵列（Terracotta Server Array，TSA）中，但是最近使用的数据(L1)，可以存储在各个应用节点中。**。逻辑视角如下图所示：

<div align="center">
<img src="https://raw.githubusercontent.com/adamhand/LeetCode-images/master/27135d72-600a-34c8-a067-d3c48dff43a9.png">
</div>

模型存储视角如下图所示：

<div align="center">
<img src="https://raw.githubusercontent.com/adamhand/LeetCode-images/master/a1471f73-1bfb-387a-a9e8-501b3dfbd0b4.png">
</div>

整体数据流转包括这样几类行为:

- Flush：缓存条目向低层次移动。
- Fault：从低层拷贝一个对象到高层。在获取缓存的过程中，某一层发现自己的该缓存条目已经失效，就触发了Fault行为。
- Eviction：把缓存条目除去。
- Expiration：失效状态。
- Pinning：强制缓存条目保持在某一层。

下图反映了数据在各个层之间的流转。

<div align="center">
<img src="https://raw.githubusercontent.com/adamhand/LeetCode-images/master/20170318085739_660.png">
</div>

虽然Ehcache支持磁盘的持久化，但是由于存在两级缓存介质，在一级内存中的缓存，如果没有主动的刷入磁盘持久化的话，在应用异常down机等情形下，依然会出现缓存数据丢失，为此可以根据需要将缓存刷到磁盘，将缓存条目刷到磁盘的操作可以通过cache.flush()方法来执行，需要注意的是，对于对象的磁盘写入，前提是要将对象进行序列化。

Ehcache的超时设置主要是针对整个cache实例设置整体的超时策略，而针对单独的key的个性的超时设置比较复杂，因此，在使用中要注意过期失效的缓存元素无法被GC回收，时间越长缓存越多，内存占用也就越大，内存泄露的概率也越大。

### Guava Cache
Guava Cache是工具集库Guava里的一款缓存工具，其主要实现的缓存功能有：

- 自动将entry节点加载进缓存结构中；
- 当缓存的数据超过设置的最大值时，使用LRU算法移除；
- 具备根据entry节点上次被访问或者写入时间计算它的过期机制；
- 缓存的key被封装在WeakReference引用内；
- 缓存的Value被封装在WeakReference或SoftReference引用内；
- 统计缓存使用过程中命中率、异常率、未命中率等统计数据。

<div align="center">
<img src="https://raw.githubusercontent.com/adamhand/LeetCode-images/master/20170318085739_803.png">
</div>

Guava Cache的思想是ConcurrentHashMap+双链表，用ConcurrentHashMap来保证线程安全，用双链表实现LRU算法。

Guava Cache中有两条双向链表：WriteQueue和AccessQueue。这两条链表都自定义了offer、add（直接调用offer）、remove、poll等操作的逻辑，具体操作如下：

- 对offer（add）操作，如果是新加的节点，则直接加入到该链的结尾，如果是已存在的节点，则将该节点链接的链尾；
- 对remove操作，直接从该链中移除该节点；
- 对poll操作，将头节点的下一个节点移除，并返回。

即，将最近使用的数据放到链表尾，淘汰数据时从链表头开始淘汰。

## 附录：各种缓存淘汰策略的实现方法
### LRU算法
可以考虑使用HashMap+双链表来实现，如果需要线程安全的话，可以使用ConcurrentHashMap，类似于Guava Cache中的实现。使用HashMap+双链表的代码如下：

```java
public class LRUCache<K, V> implements Iterable<K> {
    private Node head;         //双链表的头结点，不存储值
    private Node tail;         //双链表的尾结点，不存储值
    private int size;          //链表的最大容量
    private float loadFactor = 0.75f;  //HashMap中的容量为size * loadFactor
    private HashMap<K, Node> map;

    private class Node{
        Node pre;
        Node next;
        K k;
        V v;

        public Node(K k, V v){
            this.k = k;
            this.v = v;
        }
    }

    public LRUCache(int size){
        this.size = size;
        map = new HashMap<K, Node>((int)(size * loadFactor));

        head = new Node(null, null);
        tail = new Node(null, null);

        //构建一个空的双链表
        head.next = tail;
        tail.next = head;
    }

    public V get(K key){
        if(! map.containsKey(key)){
            return null;
        }

        Node node = map.get(key);
        unlink(node);
        appendHead(node);

        return node.v;
    }

    public void put(K key, V value){
        if(map.containsKey(key)){
            Node node = map.get(key);
            unlink(node);
        }

        Node node = new Node(key, value);
        map.put(key, node);
        appendHead(node);

        if(map.size() > size){
            Node toRemove = removeTail();
            map.remove(toRemove.k);
        }
    }

    //将当前元素在双链表中断开
    private void unlink(Node node){
        Node pre = node.pre;
        Node next = node.next;

        pre.next = next;
        next.pre = pre;

        node.pre = null;
        node.next = null;
    }

    //将当前节点加入链表头
    private Node appendHead(Node node){
//        unlink(node);

        Node headNext = head.next;
        head.next = node;
        node.next = headNext;

        headNext.pre = node;
        node.pre = head;

        return node;
    }

    //删除链表尾部的节点
    private Node removeTail(){
        Node node = tail.pre;
        Node pre = node.pre;

        tail.pre = pre;
        pre.next = tail;

        node.pre = null;
        node.next = null;

        return node;
    }

    @Override
    public Iterator<K> iterator() {
        return new Iterator<K>() {
            private Node cur = head.next;

            @Override
            public boolean hasNext() {
                return cur != tail;
            }

            @Override
            public K next() {
                Node node = cur;
                cur = cur.next;
                return node.k;
            }

            @Override
            public void remove() {

            }
        };
    }
}
```

### LFU 算法

使用HashMap+TreeMap来实现。HashMap还是存储元素，TreeMap用来存储每个元素使用的次数，并且根据次数排序，每次淘汰使用次数最少的。TreeMap中的key为某个node的使用次数，value为一个链表，存放的元素是使用次数相同的node。

```java
public class LFUCache<K, V> implements Iterable<V>{
    private int size;
    private TreeMap<Integer, List<Node<K, V>>> countMap = null;
    private HashMap<K, Node<K, V>> cache = null;

    private class Node<K, V> {
        K key;
        V value;
        int count;

        Node (K key, V value) {
            this.key = key;
            this.value = value;
        }

        Node (K key, V value, int count) {
            this.key = key;
            this.value = value;
            this.count = count;
        }

        public K getKey() {
            return key;
        }

        public void setKey(K key) {
            this.key = key;
        }

        public V getValue() {
            return value;
        }

        public void setValue(V value) {
            this.value = value;
        }

        public int getCount() {
            return count;
        }

        public void setCount(int count) {
            this.count = count;
        }
    }

    LFUCache(int size) {
        if (size < 0) {
            throw new IllegalArgumentException("invalid size");
        }
        cache = new HashMap<K, Node<K, V>>(size);
        countMap = new TreeMap<Integer, List<Node<K,V>>>(new Comparator<Integer>() {
            @Override
            public int compare(Integer o1, Integer o2) {
                return o1 - o2;
            }
        });
        this.size = size;
    }

    public void put(K key, V value) {
        if (cache.containsKey(key)) {
            Node node = cache.get(key);
            int count = node.getCount();
            node.setCount(count + 1);

            rmCountNode(count, node);
            addCountNode(count + 1, node);
        }

        Node node = new Node(key, value);
        cache.put(key, node);
        addCountNode(node.getCount(), node);

        if (cache.size() == size + 1) {
            Map.Entry<Integer, List<Node<K, V>>> entry = countMap.firstEntry();
            Node node1 = entry.getValue().get(0);
            rmCountNode(node1.getCount(), node1);
            cache.remove(node1.getKey());
        }
    }

    public V get(K key) {
        if (!cache.containsKey(key))
            return  null;

        Node<K, V> node = cache.get(key);
        rmCountNode(node.getCount(), node);
        addCountNode(node.getCount() + 1, node);
        node.setCount(node.getCount() + 1);

        return node.getValue();
    }

    private void addCountNode (int count, Node<K, V> node) {
        List<Node<K, V>> list = countMap.get(count);
        if (null == list) {
            list = new ArrayList<Node<K, V>>();
            countMap.put(count, list);
        }
        list.add(node);
    }

    private void rmCountNode(int count, Node<K, V> node) {
        List<Node<K, V>> list = countMap.get(count);
        if (list.size() == 1) {
            countMap.remove(count);
        } else {
            list.remove(node);
        }
    }

    @Override
    public Iterator<V> iterator() {
        return new Iterator<V>() {
            private Iterator<Map.Entry<K, Node<K, V>>> it = cache.entrySet().iterator();

            @Override
            public boolean hasNext() {
                return it.hasNext();
            }

            @Override
            public V next() {
                return it.next().getValue().getValue();
            }
        };
    }
}
```


### FIFO 算法
很容易想到用队列来实现，还是使用HashMap存储元素。

```java
public class FIFOCache <K, V> implements Iterable<V> {
    private int size;
    private HashMap<K, Node<K, V>> cache;
    private Queue<K> queue;

    private class Node <K, V> {
        K key;
        V value;

        Node (K key, V value) {
            this.key = key;
            this.value = value;
        }
    }

    FIFOCache (int size) {
        if (size < 0) {
            throw new IllegalArgumentException("invalid size");
        }

        this.size = size;
        cache = new HashMap<>(size);
        queue = new LinkedList<>();
    }

    public void put (K key, V value) {
        if (cache.containsKey(key)) {
            queue.remove(key);
        }

        Node node = new Node(key, value);
        cache.put(key, node);
        queue.add(key);

        if (cache.size() == size + 1) {
            K k = queue.poll();
            queue.remove(k);
            cache.remove(k);
        }
    }

    public V get (K key) {
        if (!cache.containsKey(key)) {
            return null;
        }
        return cache.get(key).value;
    }

    @Override
    public Iterator<V> iterator() {
        return new Iterator<V>() {
            private Iterator<Map.Entry<K, Node<K, V>>> it = cache.entrySet().iterator();

            @Override
            public boolean hasNext() {
                return it.hasNext();
            }

            @Override
            public V next() {
                return it.next().getValue().value;
            }
        };
    }
}
```

## 附录：memcached安装和使用

## 附录：Ehcache使用

## 附录：Guava Cache使用

## 参考
[一致性哈希算法](https://my.oschina.net/jayhu/blog/732849)</br>
[缓存常见问题](https://blog.csdn.net/weixin_43164644/article/details/83719385)</br>
[缓存那些事](https://tech.meituan.com/2017/03/17/cache-about.html)</br>
[ehcache详解](https://www.cnblogs.com/deepbreath/p/5456413.html)</br>
[缓存淘汰策略](https://www.codercto.com/a/56851.html)</br>
[LFUCache Java实现](https://blog.csdn.net/chenxuegui1234/article/details/90380317)</br>
[算法日记——LRU和LFU的O(1)实现](https://blog.csdn.net/qq_32198277/article/details/79773695)</br>
[常用缓存淘汰策略FIFO、LFU、LRU](https://www.jianshu.com/p/4cd5509eec3d)</br>
[memcached 缓存数据库应用实践](https://www.cnblogs.com/clsn/p/7999510.html#auto_id_3)</br>
[Memcached缓存介绍](https://blog.csdn.net/qincidong/article/details/88964369)</br>
[Ehcache缓存框架详解](https://blog.csdn.net/qq_28702545/article/details/69397361)
